import streamlit as st
import cv2
import numpy as np
import tempfile
import os
from datetime import datetime
from collections import defaultdict
from ultralytics import YOLO

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Pine Flower Phenology Recognition",
    page_icon="ğŸŒ²",
    layout="wide"
)
# ğŸ¯ æ¨¡å‹æ–‡ä»¶æ£€æŸ¥
model_path = 'models/best.pt'
if os.path.exists(model_path):
    st.sidebar.success(f"âœ… æ¨¡å‹æ–‡ä»¶åŠ è½½æˆåŠŸ ({os.path.getsize(model_path)/1024/1024:.1f} MB)")
else:
    st.sidebar.error("âŒ æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°")

# æ¾èŠ±æ—¶æœŸç±»åˆ«æ˜ å°„
PINE_FLOWER_CLASSES = {
    0: {'name': 'elongation stage', 'color': (0, 255, 0), 'display_name': 'Elongation Stage'},
    1: {'name': 'ripening stage', 'color': (0, 165, 255), 'display_name': 'Ripening Stage'},
    2: {'name': 'decline stage', 'color': (0, 0, 255), 'display_name': 'Decline Stage'}
}


class StreamlitDetector:
    def __init__(self, model_path):
        self.model_path = model_path
        self.model = None
        self.load_model()

    def load_model(self):
        """åŠ è½½YOLOv11æ¨¡å‹"""
        try:
            self.model = YOLO(self.model_path)
        except Exception as e:
            st.error(f"Model loading failed: {e}")
            self.model = None

    def detect_image(self, image):
        """æ‰§è¡Œå›¾ç‰‡æ£€æµ‹"""
        try:
            st.write("---")
            st.write("ğŸ” **å¼€å§‹æ£€æµ‹è¿‡ç¨‹**")
            st.write(f"ğŸ“ è¾“å…¥å›¾åƒå°ºå¯¸: {image.shape}")

            if self.model is not None:
                st.write("âœ… ä½¿ç”¨YOLOæ¨¡å‹è¿›è¡Œæ£€æµ‹...")

                # æ‰§è¡Œæ£€æµ‹
                results = self.model(image)
                st.write(f"ğŸ“Š YOLOè¿”å› {len(results)} ä¸ªæ£€æµ‹ç»“æœ")

                detections = []
                for i, result in enumerate(results):
                    boxes = result.boxes
                    if boxes is not None:
                        st.write(f"ğŸ¯ ç»“æœ {i + 1}: æ£€æµ‹åˆ° {len(boxes)} ä¸ªç›®æ ‡")

                        for j, box in enumerate(boxes):
                            class_id = int(box.cls.item())
                            confidence = box.conf.item()
                            bbox = box.xyxy[0].tolist()

                            st.write(f"   ğŸ“¦ ç›®æ ‡ {j + 1}:")
                            st.write(
                                f"     ç±»åˆ«: {class_id} ({PINE_FLOWER_CLASSES.get(class_id, {}).get('display_name', 'Unknown')})")
                            st.write(f"     ç½®ä¿¡åº¦: {confidence:.3f}")
                            st.write(f"     ä½ç½®: [{bbox[0]:.1f}, {bbox[1]:.1f}, {bbox[2]:.1f}, {bbox[3]:.1f}]")

                            class_info = PINE_FLOWER_CLASSES.get(class_id, {
                                'name': 'unknown', 'color': (255, 255, 255), 'display_name': 'Unknown Stage'
                            })

                            detections.append({
                                'bbox': bbox,
                                'confidence': confidence,
                                'class_name': class_info['name'],
                                'display_name': class_info['display_name'],
                                'class_id': class_id,
                                'color': class_info['color']
                            })
                    else:
                        st.warning(f"âš ï¸ ç»“æœ {i + 1}: æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡")

                st.write(f"ğŸ‰ æ€»å…±æ£€æµ‹åˆ°: {len(detections)} ä¸ªæ¾èŠ±")

            else:
                st.warning("âš ï¸ æ¨¡å‹æœªåŠ è½½ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ£€æµ‹")
                detections = self.mock_detect(image)

            # ç»˜åˆ¶æ£€æµ‹ç»“æœ
            st.write("ğŸ–Œï¸ å¼€å§‹ç»˜åˆ¶æ£€æµ‹æ¡†...")
            result_image = self.draw_detections(image.copy(), detections)
            return detections, result_image

        except Exception as e:
            st.error(f"âŒ æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            import traceback
            st.error("é”™è¯¯è¯¦æƒ…:")
            st.code(traceback.format_exc())
            return self.mock_detect(image), image

    def detect_video(self, video_path):
        """æ‰§è¡Œè§†é¢‘æ£€æµ‹"""
        try:
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                st.error("Cannot open video file")
                return [], None

            # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶
            output_path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name

            fps = int(cap.get(cv2.CAP_PROP_FPS))
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

            progress_bar = st.progress(0)
            status_text = st.empty()

            frame_count = 0
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            video_detections = []

            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                # æ›´æ–°è¿›åº¦
                if frame_count % 10 == 0:
                    progress = frame_count / total_frames
                    progress_bar.progress(progress)
                    status_text.text(f"Processing frame {frame_count}/{total_frames}")

                # æ¯5å¸§æ£€æµ‹ä¸€æ¬¡
                if frame_count % 5 == 0:
                    if self.model is not None:
                        results = self.model(frame)
                        frame_detections = []
                        for result in results:
                            for box in result.boxes:
                                class_id = int(box.cls.item())
                                class_info = PINE_FLOWER_CLASSES.get(class_id, {
                                    'name': 'unknown', 'color': (255, 255, 255), 'display_name': 'Unknown Stage'
                                })

                                frame_detections.append({
                                    'bbox': box.xyxy[0].tolist(),
                                    'confidence': box.conf.item(),
                                    'class_name': class_info['name'],
                                    'display_name': class_info['display_name'],
                                    'class_id': class_id,
                                    'color': class_info['color']
                                })
                    else:
                        frame_detections = self.mock_detect(frame)

                    video_detections.extend(frame_detections)

                # ç»˜åˆ¶æ£€æµ‹æ¡†
                result_frame = self.draw_detections(frame.copy(), frame_detections if frame_count % 5 == 0 else [])
                out.write(result_frame)
                frame_count += 1

            cap.release()
            out.release()
            progress_bar.progress(1.0)
            status_text.text("Processing completed!")

            return video_detections, output_path

        except Exception as e:
            st.error(f"Video processing failed: {e}")
            return [], None

    def mock_detect(self, image):
        """æ¨¡æ‹Ÿæ£€æµ‹"""
        height, width = image.shape[:2]
        detections = []
        import random
        num_detections = random.randint(2, 4)

        for i in range(num_detections):
            x1 = random.randint(50, width - 150)
            y1 = random.randint(50, height - 150)
            x2 = x1 + random.randint(80, 200)
            y2 = y1 + random.randint(80, 200)
            confidence = round(0.7 + random.random() * 0.25, 2)
            class_id = random.randint(0, 2)
            class_info = PINE_FLOWER_CLASSES[class_id]

            detections.append({
                'bbox': [x1, y1, x2, y2],
                'confidence': confidence,
                'class_name': class_info['name'],
                'display_name': class_info['display_name'],
                'class_id': class_id,
                'color': class_info['color']
            })
        return detections

    def draw_detections(self, image, detections):
        """ç»˜åˆ¶æ£€æµ‹æ¡†"""
        st.write(f"ğŸ–Œï¸ éœ€è¦ç»˜åˆ¶ {len(detections)} ä¸ªæ£€æµ‹æ¡†")

        if len(detections) == 0:
            st.warning("âš ï¸ æ²¡æœ‰æ£€æµ‹æ¡†éœ€è¦ç»˜åˆ¶ï¼Œè¿”å›åŸå›¾")
            return image

        # è·å–å›¾åƒå°ºå¯¸
        image_height, image_width = image.shape[:2]
        st.write(f"ğŸ“ ç”»å¸ƒå°ºå¯¸: å®½={image_width}, é«˜={image_height}")

        for i, det in enumerate(detections):
            x1, y1, x2, y2 = map(int, det['bbox'])
            conf = det['confidence']
            color = det.get('color', (0, 255, 0))
            display_name = det['display_name']

            st.write(f"  ğŸ¨ ç»˜åˆ¶ç¬¬ {i + 1} ä¸ªæ¡†: {display_name}")
            st.write(f"     ç½®ä¿¡åº¦: {conf:.2f}")
            st.write(f"     åæ ‡: [{x1}, {y1}, {x2}, {y2}]")

            # æ£€æŸ¥åæ ‡æ˜¯å¦åˆç†
            if x1 >= x2 or y1 >= y2:
                st.error(f"     âŒ åæ ‡æ— æ•ˆ: x1>=x2 æˆ– y1>=y2")
                continue

            if x1 < 0 or y1 < 0 or x2 > image_width or y2 > image_height:
                st.warning(f"     âš ï¸ åæ ‡éƒ¨åˆ†è¶…å‡ºå›¾åƒèŒƒå›´")

            # ç”»æ£€æµ‹æ¡†
            cv2.rectangle(image, (x1, y1), (x2, y2), color, 3)
            st.write(f"     âœ… å·²ç»˜åˆ¶è¾¹ç•Œæ¡†")

            # ç”»æ ‡ç­¾èƒŒæ™¯
            label = f"{display_name} {conf:.2f}"
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]

            # è®¡ç®—æ ‡ç­¾ä½ç½®ï¼ˆç¡®ä¿ä¸è¶…å‡ºå›¾åƒä¸Šè¾¹ç•Œï¼‰
            label_bg_y1 = max(y1 - label_size[1] - 10, 0)
            label_bg_y2 = y1
            label_bg_x2 = x1 + label_size[0] + 5

            cv2.rectangle(image, (x1, label_bg_y1), (label_bg_x2, label_bg_y2), color, -1)
            st.write(f"     âœ… å·²ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯")

            # ç”»æ–‡å­—
            text_y = max(y1 - 5, label_size[1] - 5)
            cv2.putText(image, label, (x1, text_y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            st.write(f"     âœ… å·²ç»˜åˆ¶æ–‡å­—æ ‡ç­¾")

        st.success("ğŸ¨ æ‰€æœ‰æ£€æµ‹æ¡†ç»˜åˆ¶å®Œæˆ!")
        return image

    def get_statistics(self, detections):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {'total_count': 0, 'by_stage': defaultdict(int)}
        if not detections:
            return stats

        stats['total_count'] = len(detections)
        for det in detections:
            stage = det['display_name']
            stats['by_stage'][stage] += 1

        return stats


# åˆå§‹åŒ–æ£€æµ‹å™¨
@st.cache_resource
def load_detector():
    return StreamlitDetector('models/best.pt')


def main():
    # æ ‡é¢˜
    st.title("ğŸŒ² Pine Flower Phenology Recognition System")
    st.markdown("Based on YOLOv11 - Detect elongation, ripening, and decline stages")

    # ä¾§è¾¹æ 
    st.sidebar.title("About")
    st.sidebar.info("This system uses YOLOv11 to detect and classify pine flower phenology stages.")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader(
        "Choose an image or video file",
        type=['png', 'jpg', 'jpeg', 'mp4', 'avi', 'mov'],
        help="Supported formats: JPG, PNG, MP4, AVI, MOV"
    )

    if uploaded_file is not None:
        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
        file_details = {
            "Filename": uploaded_file.name,
            "File size": f"{uploaded_file.size / 1024 / 1024:.2f} MB",
            "File type": uploaded_file.type
        }
        st.write("File details:", file_details)

        # åŠ è½½æ£€æµ‹å™¨
        detector = load_detector()

        if st.button("Start Detection", type="primary"):
            with st.spinner("Processing..."):
                # æ ¹æ®æ–‡ä»¶ç±»å‹å¤„ç†
                if uploaded_file.type.startswith('image'):
                    # å›¾ç‰‡å¤„ç†
                    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
                    image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
                    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

                    # æ£€æµ‹
                    detections, result_image = detector.detect_image(image)
                    result_image_rgb = cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)

                    # æ˜¾ç¤ºç»“æœ
                    col1, col2 = st.columns(2)
                    with col1:
                        st.subheader("Original Image")
                        st.image(image_rgb, use_column_width=True)
                    with col2:
                        st.subheader("Detection Result")
                        st.image(result_image_rgb, use_column_width=True)

                elif uploaded_file.type.startswith('video'):
                    # è§†é¢‘å¤„ç†
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
                        tmp_file.write(uploaded_file.read())
                        tmp_path = tmp_file.name

                    # æ£€æµ‹
                    detections, result_path = detector.detect_video(tmp_path)

                    # æ˜¾ç¤ºç»“æœ
                    col1, col2 = st.columns(2)
                    with col1:
                        st.subheader("Original Video")
                        st.video(uploaded_file)
                    with col2:
                        st.subheader("Detection Result")
                        if result_path:
                            with open(result_path, 'rb') as f:
                                st.video(f.read())

                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    os.unlink(tmp_path)
                    if result_path and os.path.exists(result_path):
                        os.unlink(result_path)

                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                st.subheader("ğŸ“Š Detection Statistics")
                stats = detector.get_statistics(detections)

                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Total Detections", stats['total_count'])

                with col2:
                    for stage, count in stats['by_stage'].items():
                        st.metric(f"{stage}", count)

                # æ˜¾ç¤ºæ£€æµ‹è¯¦æƒ…
                st.subheader("ğŸ” Detection Details")
                if detections:
                    for i, det in enumerate(detections):
                        st.write(
                            f"**Pine Flower {i + 1}**: {det['display_name']} (Confidence: {det['confidence']:.2f})")
                else:
                    st.info("No pine flowers detected")

                st.success(f"Detection completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    main()
